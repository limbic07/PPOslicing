import os
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor
from env_5g_sla import FiveG_SLA_Env

# --- é…ç½®è·¯å¾„ ---
# è¯»å–æ—§æ¨¡å‹å’Œæ—§ç»Ÿè®¡æ•°æ®çš„è·¯å¾„
old_models_dir = "./models_formal/"
old_model_path = os.path.join(old_models_dir, "best_model.zip")
old_stats_path = os.path.join(old_models_dir, "vec_normalize.pkl")

# æ–°çš„æ—¥å¿—è·¯å¾„ (å¯é€‰ï¼šä½ å¯ä»¥å­˜åˆ°åŒä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œä¹Ÿå¯ä»¥æ–°å»º)
log_dir = "./logs_formal/"


def make_env():
    env = FiveG_SLA_Env()
    return Monitor(env)


if __name__ == "__main__":
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ—§æ¨¡å‹å’Œç¯å¢ƒå‚æ•°: {old_model_path}")

    # --- 1. é‡å»ºç¯å¢ƒå¹¶åŠ è½½ç»Ÿè®¡å‚æ•° (å…³é”®!) ---
    # å…ˆåˆ›å»ºä¸€ä¸ªç©ºç¯å¢ƒ
    env = DummyVecEnv([make_env])

    # åŠ è½½ä¹‹å‰çš„å‡å€¼å’Œæ–¹å·® (VecNormalize)
    # training=True: æˆ‘ä»¬è¦ç»§ç»­è®­ç»ƒï¼Œæ‰€ä»¥è¦ç»§ç»­æ›´æ–°ç»Ÿè®¡æ•°æ®
    # norm_reward=True: å¥–åŠ±ä¹Ÿç»§ç»­å½’ä¸€åŒ–
    env = VecNormalize.load(old_stats_path, env)
    env.training = True
    env.norm_reward = True

    # åŒæ—¶ä¹Ÿéœ€è¦ä¸ºè¯„ä¼°ç¯å¢ƒåŠ è½½åŒæ ·çš„å‚æ•°
    eval_env = DummyVecEnv([make_env])
    eval_env = VecNormalize.load(old_stats_path, eval_env)
    eval_env.training = True
    eval_env.norm_reward = True

    # ... (å‰é¢çš„ä»£ç ä¸å˜) ...

    # --- 2. åŠ è½½æ¨¡å‹ ---
    model = PPO.load(old_model_path, env=env, device="cpu")

    # ==========================================
    # ğŸ› ï¸ ã€æ ¸å¿ƒä¿®å¤ã€‘æ‰‹åŠ¨æ ¡å‡†æ—¶é—´æ­¥
    # ==========================================
    # ä½ å¿…é¡»çŸ¥é“ä¸Šä¸€è½®è®­ç»ƒæ€»å…±è·‘äº†å¤šå°‘æ­¥ (æ¯”å¦‚ 500,000)
    # æˆ–è€…å» TensorBoard çœ‹ä¸€çœ¼æœ€åä¸€æ­¥æ˜¯å¤šå°‘
    PREVIOUS_TOTAL_STEPS = 500_000  # <--- è¯·ä¿®æ”¹ä¸ºä½ å®é™…ä¸Šä¸€æ¬¡ç»“æŸæ—¶çš„æ€»æ­¥æ•°

    print(f"æ ¡å‡†æ­¥æ•°: æ¨¡å‹è®°å½•æ­¥æ•° {model.num_timesteps} -> å¼ºåˆ¶ä¿®æ­£ä¸º {PREVIOUS_TOTAL_STEPS}")
    model.num_timesteps = PREVIOUS_TOTAL_STEPS




    # --- 3. è®¾ç½®å›è°ƒå‡½æ•° ---
    # ç»§ç»­ä¿å­˜æœ€å¥½çš„æ¨¡å‹
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=old_models_dir,
        log_path=log_dir,
        eval_freq=10000,
        deterministic=True,
        render=False
    )
    # --- 4. ç»§ç»­è®­ç»ƒ ---
    MORE_TIMESTEPS = 200_000
    print(f"ğŸš€ å¼€å§‹ç»­è®­ (è¿½åŠ  {MORE_TIMESTEPS} æ­¥)...")

    # reset_num_timesteps=False å¿…é¡»ä¿ç•™
    # tb_log_name å»ºè®®ä¿æŒä¸€è‡´ï¼Œè¿™æ ·ä¼šå†™åœ¨åŒä¸€ä¸ª PPO_x æ–‡ä»¶å¤¹ä¸‹(å¦‚æœæ²¡è¢«å ç”¨)
    # æˆ–è€…ä½ å¯ä»¥æŒ‡å®šä¸€ä¸ªæ–°çš„åå­—ï¼ŒTensorBoard ä¼šè‡ªåŠ¨æŠŠå®ƒä»¬è¿èµ·æ¥æ˜¾ç¤º
    model.learn(total_timesteps=MORE_TIMESTEPS,
                callback=eval_callback,
                reset_num_timesteps=False)  # è¿™é‡Œçš„ False é…åˆä¸Šé¢çš„æ‰‹åŠ¨ä¿®æ”¹æ‰æœ‰æ•ˆ


    # --- 5. ä¿å­˜ç»“æœ ---
    model.save(f"{old_models_dir}/final_model_extended")
    env.save(f"{old_models_dir}/vec_normalize.pkl")  # è¦†ç›–æ›´æ–°ç»Ÿè®¡æ–‡ä»¶

    print("âœ… ç»­è®­å®Œæˆï¼æ¨¡å‹å·²æ›´æ–°ã€‚")